{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fraud Data Exploratory Data Analysis (EDA)\n",
        "\n",
        "This notebook performs comprehensive EDA on the fraud dataset to understand:\n",
        "1. Data structure and schema\n",
        "2. Data quality and missing values\n",
        "3. Fraud patterns and distributions\n",
        "4. Temporal analysis\n",
        "5. Geographic analysis (if available)\n",
        "6. Value analysis for H1 2023\n",
        "\n",
        "Run this notebook to understand the data before fixing backend issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== LOADING FRAUD DATA ===\n",
            "Data directory: ..\\dataset\n",
            "Train file exists: True\n",
            "Test file exists: True\n",
            "Train data shape: (1296675, 23)\n",
            "Test data shape: (555719, 23)\n"
          ]
        }
      ],
      "source": [
        "# Load fraud data from CSV files\n",
        "print(\"=== LOADING FRAUD DATA ===\")\n",
        "\n",
        "# Define paths\n",
        "data_dir = Path(\"../dataset\")\n",
        "train_file = data_dir / \"archive\" / \"fraudTrain.csv\"\n",
        "test_file = data_dir / \"archive\" / \"fraudTest.csv\"\n",
        "\n",
        "print(f\"Data directory: {data_dir}\")\n",
        "print(f\"Train file exists: {train_file.exists()}\")\n",
        "print(f\"Test file exists: {test_file.exists()}\")\n",
        "\n",
        "# Load data\n",
        "if train_file.exists():\n",
        "    train_df = pd.read_csv(train_file)\n",
        "    print(f\"Train data shape: {train_df.shape}\")\n",
        "else:\n",
        "    print(\"Train file not found!\")\n",
        "    train_df = None\n",
        "\n",
        "if test_file.exists():\n",
        "    test_df = pd.read_csv(test_file)\n",
        "    print(f\"Test data shape: {test_df.shape}\")\n",
        "else:\n",
        "    print(\"Test file not found!\")\n",
        "    test_df = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Basic Data Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TRAIN DATASET BASIC INFO ===\n",
            "Shape: (1296675, 23)\n",
            "Columns: ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud']\n",
            "\n",
            "Data types:\n",
            "Unnamed: 0                 int64\n",
            "trans_date_trans_time     object\n",
            "cc_num                     int64\n",
            "merchant                  object\n",
            "category                  object\n",
            "amt                      float64\n",
            "first                     object\n",
            "last                      object\n",
            "gender                    object\n",
            "street                    object\n",
            "city                      object\n",
            "state                     object\n",
            "zip                        int64\n",
            "lat                      float64\n",
            "long                     float64\n",
            "city_pop                   int64\n",
            "job                       object\n",
            "dob                       object\n",
            "trans_num                 object\n",
            "unix_time                  int64\n",
            "merch_lat                float64\n",
            "merch_long               float64\n",
            "is_fraud                   int64\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "Unnamed: 0               0\n",
            "trans_date_trans_time    0\n",
            "cc_num                   0\n",
            "merchant                 0\n",
            "category                 0\n",
            "amt                      0\n",
            "first                    0\n",
            "last                     0\n",
            "gender                   0\n",
            "street                   0\n",
            "city                     0\n",
            "state                    0\n",
            "zip                      0\n",
            "lat                      0\n",
            "long                     0\n",
            "city_pop                 0\n",
            "job                      0\n",
            "dob                      0\n",
            "trans_num                0\n",
            "unix_time                0\n",
            "merch_lat                0\n",
            "merch_long               0\n",
            "is_fraud                 0\n",
            "dtype: int64\n",
            "\n",
            "First few rows:\n"
          ]
        }
      ],
      "source": [
        "if train_df is not None:\n",
        "    print(\"=== TRAIN DATASET BASIC INFO ===\")\n",
        "    print(f\"Shape: {train_df.shape}\")\n",
        "    print(f\"Columns: {list(train_df.columns)}\")\n",
        "    print(f\"\\nData types:\")\n",
        "    print(train_df.dtypes)\n",
        "    print(f\"\\nMissing values:\")\n",
        "    print(train_df.isnull().sum())\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    train_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. H1 2023 Value Analysis (Critical for Backend Fix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== H1 2023 VALUE ANALYSIS ===\n",
            "H1 2023 data shape: (0, 23)\n",
            "No H1 2023 data found!\n"
          ]
        }
      ],
      "source": [
        "if train_df is not None and 'trans_date_trans_time' in train_df.columns and 'amt' in train_df.columns:\n",
        "    print(\"=== H1 2023 VALUE ANALYSIS ===\")\n",
        "    \n",
        "    # Filter for H1 2023\n",
        "    train_df['trans_date_trans_time'] = pd.to_datetime(train_df['trans_date_trans_time'])\n",
        "    h1_2023 = train_df[(train_df['trans_date_trans_time'] >= '2023-01-01') & \n",
        "                       (train_df['trans_date_trans_time'] < '2023-07-01')]\n",
        "    \n",
        "    print(f\"H1 2023 data shape: {h1_2023.shape}\")\n",
        "    \n",
        "    if len(h1_2023) > 0:\n",
        "        # Fraud value analysis\n",
        "        fraud_data = h1_2023[h1_2023['is_fraud'] == 1]\n",
        "        total_fraud_value = fraud_data['amt'].sum()\n",
        "        total_fraud_count = len(fraud_data)\n",
        "        \n",
        "        print(f\"Total fraud transactions in H1 2023: {total_fraud_count:,}\")\n",
        "        print(f\"Total fraud value in H1 2023: ${total_fraud_value:,.2f}\")\n",
        "        \n",
        "        # High-value vs low-value analysis (proxy for cross-border)\n",
        "        high_value_threshold = 100\n",
        "        high_value_fraud = fraud_data[fraud_data['amt'] > high_value_threshold]\n",
        "        low_value_fraud = fraud_data[fraud_data['amt'] <= high_value_threshold]\n",
        "        \n",
        "        high_value_amount = high_value_fraud['amt'].sum()\n",
        "        low_value_amount = low_value_fraud['amt'].sum()\n",
        "        \n",
        "        print(f\"\\nHigh-value fraud (>${high_value_threshold}):\")\n",
        "        print(f\"  Count: {len(high_value_fraud):,}\")\n",
        "        print(f\"  Value: ${high_value_amount:,.2f}\")\n",
        "        print(f\"  Share: {(high_value_amount/total_fraud_value)*100:.2f}%\")\n",
        "        \n",
        "        print(f\"\\nLow-value fraud (â‰¤${high_value_threshold}):\")\n",
        "        print(f\"  Count: {len(low_value_fraud):,}\")\n",
        "        print(f\"  Value: ${low_value_amount:,.2f}\")\n",
        "        print(f\"  Share: {(low_value_amount/total_fraud_value)*100:.2f}%\")\n",
        "        \n",
        "        # Create the data structure expected by the backend\n",
        "        value_analysis_data = pd.DataFrame({\n",
        "            'transaction_type': ['Cross-border (High-value proxy)', 'Domestic (Low-value proxy)'],\n",
        "            'fraud_value': [high_value_amount, low_value_amount],\n",
        "            'fraud_count': [len(high_value_fraud), len(low_value_fraud)],\n",
        "            'percentage_share': [(high_value_amount/total_fraud_value)*100, (low_value_amount/total_fraud_value)*100],\n",
        "            'total_fraud_value': [total_fraud_value, total_fraud_value]\n",
        "        })\n",
        "        \n",
        "        print(f\"\\nValue analysis data structure (for backend):\")\n",
        "        print(value_analysis_data)\n",
        "        \n",
        "        # Visualize the results\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        \n",
        "        # Pie chart of fraud value distribution\n",
        "        ax1.pie(value_analysis_data['fraud_value'], \n",
        "                labels=value_analysis_data['transaction_type'], \n",
        "                autopct='%1.1f%%', \n",
        "                startangle=90)\n",
        "        ax1.set_title('H1 2023 Fraud Value Distribution\\n(High-value as Cross-border proxy)')\n",
        "        \n",
        "        # Bar chart of fraud counts\n",
        "        ax2.bar(value_analysis_data['transaction_type'], value_analysis_data['fraud_count'])\n",
        "        ax2.set_title('H1 2023 Fraud Count by Type')\n",
        "        ax2.set_ylabel('Fraud Count')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "    else:\n",
        "        print(\"No H1 2023 data found!\")\n",
        "else:\n",
        "    print(\"Required columns not found for H1 2023 analysis!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Database Schema Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DATABASE SCHEMA CHECK ===\n",
            "Tables in database: ['transactions']\n",
            "\n",
            "Transactions table columns:\n",
            "  Unnamed: 0 (INTEGER)\n",
            "  trans_date_trans_time (TEXT)\n",
            "  cc_num (INTEGER)\n",
            "  merchant (TEXT)\n",
            "  category (TEXT)\n",
            "  amt (REAL)\n",
            "  first (TEXT)\n",
            "  last (TEXT)\n",
            "  gender (TEXT)\n",
            "  street (TEXT)\n",
            "  city (TEXT)\n",
            "  state (TEXT)\n",
            "  zip (INTEGER)\n",
            "  lat (REAL)\n",
            "  long (REAL)\n",
            "  city_pop (INTEGER)\n",
            "  job (TEXT)\n",
            "  dob (TEXT)\n",
            "  trans_num (TEXT)\n",
            "  unix_time (INTEGER)\n",
            "  merch_lat (REAL)\n",
            "  merch_long (REAL)\n",
            "  is_fraud (INTEGER)\n",
            "\n",
            "Sample data (first 5 rows):\n",
            "  (0, '2019-01-01 00:00:18', 2703186189652095, 'fraud_Rippin, Kub and Mann', 'misc_net', 4.97, 'Jennifer', 'Banks', 'F', '561 Perry Cove', 'Moravian Falls', 'NC', 28654, 36.0788, -81.1781, 3495, 'Psychologist, counselling', '1988-03-09', '0b242abb623afc578575680df30655b9', 1325376018, 36.011293, -82.048315, 0)\n",
            "  (1, '2019-01-01 00:00:44', 630423337322, 'fraud_Heller, Gutmann and Zieme', 'grocery_pos', 107.23, 'Stephanie', 'Gill', 'F', '43039 Riley Greens Suite 393', 'Orient', 'WA', 99160, 48.8878, -118.2105, 149, 'Special educational needs teacher', '1978-06-21', '1f76529f8574734946361c461b024d99', 1325376044, 49.159047, -118.186462, 0)\n",
            "  (2, '2019-01-01 00:00:51', 38859492057661, 'fraud_Lind-Buckridge', 'entertainment', 220.11, 'Edward', 'Sanchez', 'M', '594 White Dale Suite 530', 'Malad City', 'ID', 83252, 42.1808, -112.262, 4154, 'Nature conservation officer', '1962-01-19', 'a1a22d70485983eac12b5b88dad1cf95', 1325376051, 43.150704, -112.154481, 0)\n",
            "  (3, '2019-01-01 00:01:16', 3534093764340240, 'fraud_Kutch, Hermiston and Farrell', 'gas_transport', 45.0, 'Jeremy', 'White', 'M', '9443 Cynthia Court Apt. 038', 'Boulder', 'MT', 59632, 46.2306, -112.1138, 1939, 'Patent attorney', '1967-01-12', '6b849c168bdad6f867558c3793159a81', 1325376076, 47.034331, -112.561071, 0)\n",
            "  (4, '2019-01-01 00:03:06', 375534208663984, 'fraud_Keeling-Crist', 'misc_pos', 41.96, 'Tyler', 'Garcia', 'M', '408 Bradley Rest', 'Doe Hill', 'VA', 24433, 38.4207, -79.4629, 99, 'Dance movement psychotherapist', '1986-03-28', 'a41d7549acf90789359a9aa5346dcb46', 1325376186, 38.674999, -78.632459, 0)\n",
            "\n",
            "Total transactions in database: 1,852,394\n",
            "Fraud transactions in database: 9,651\n",
            "H1 2023 transactions: 0\n",
            "H1 2023 fraud transactions: 0\n",
            "\n",
            "=== TESTING BACKEND SQL QUERY ===\n",
            "SQL query executed successfully!\n",
            "Result shape: (0, 5)\n",
            "Result data:\n",
            "Empty DataFrame\n",
            "Columns: [transaction_type, fraud_value, fraud_count, percentage_share, total_fraud_value]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print(\"=== DATABASE SCHEMA CHECK ===\")\n",
        "\n",
        "db_path = \"../fraud_data.db\"\n",
        "if Path(db_path).exists():\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Get table info\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    tables = cursor.fetchall()\n",
        "    print(f\"Tables in database: {[table[0] for table in tables]}\")\n",
        "    \n",
        "    if 'transactions' in [table[0] for table in tables]:\n",
        "        # Get column info\n",
        "        cursor.execute(\"PRAGMA table_info(transactions);\")\n",
        "        columns = cursor.fetchall()\n",
        "        print(f\"\\nTransactions table columns:\")\n",
        "        for col in columns:\n",
        "            print(f\"  {col[1]} ({col[2]})\")\n",
        "        \n",
        "        # Get sample data\n",
        "        cursor.execute(\"SELECT * FROM transactions LIMIT 5;\")\n",
        "        sample_data = cursor.fetchall()\n",
        "        print(f\"\\nSample data (first 5 rows):\")\n",
        "        for row in sample_data:\n",
        "            print(f\"  {row}\")\n",
        "        \n",
        "        # Check data counts\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM transactions;\")\n",
        "        total_count = cursor.fetchone()[0]\n",
        "        print(f\"\\nTotal transactions in database: {total_count:,}\")\n",
        "        \n",
        "        cursor.execute(\"SELECT COUNT(*) FROM transactions WHERE is_fraud = 1;\")\n",
        "        fraud_count = cursor.fetchone()[0]\n",
        "        print(f\"Fraud transactions in database: {fraud_count:,}\")\n",
        "        \n",
        "        # Check H1 2023 data\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT COUNT(*) FROM transactions \n",
        "            WHERE trans_date_trans_time >= '2023-01-01' \n",
        "            AND trans_date_trans_time < '2023-07-01'\n",
        "        \"\"\")\n",
        "        h1_2023_count = cursor.fetchone()[0]\n",
        "        print(f\"H1 2023 transactions: {h1_2023_count:,}\")\n",
        "        \n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT COUNT(*) FROM transactions \n",
        "            WHERE trans_date_trans_time >= '2023-01-01' \n",
        "            AND trans_date_trans_time < '2023-07-01'\n",
        "            AND is_fraud = 1\n",
        "        \"\"\")\n",
        "        h1_2023_fraud_count = cursor.fetchone()[0]\n",
        "        print(f\"H1 2023 fraud transactions: {h1_2023_fraud_count:,}\")\n",
        "        \n",
        "        # Test the exact SQL query from the backend\n",
        "        print(f\"\\n=== TESTING BACKEND SQL QUERY ===\")\n",
        "        test_sql = \"\"\"\n",
        "        WITH h1_2023_fraud AS (\n",
        "            SELECT \n",
        "                CASE \n",
        "                    WHEN amt > 100 THEN 'Cross-border (High-value proxy)'\n",
        "                    ELSE 'Domestic (Low-value proxy)'\n",
        "                END as transaction_type,\n",
        "                SUM(amt * is_fraud) as fraud_value,\n",
        "                COUNT(*) as total_transactions,\n",
        "                SUM(is_fraud) as fraud_count\n",
        "            FROM transactions\n",
        "            WHERE trans_date_trans_time >= '2023-01-01' \n",
        "                AND trans_date_trans_time < '2023-07-01'\n",
        "                AND is_fraud = 1\n",
        "            GROUP BY \n",
        "                CASE \n",
        "                    WHEN amt > 100 THEN 'Cross-border (High-value proxy)'\n",
        "                    ELSE 'Domestic (Low-value proxy)'\n",
        "                END\n",
        "        ),\n",
        "        total_fraud AS (\n",
        "            SELECT SUM(fraud_value) as total_fraud_value\n",
        "            FROM h1_2023_fraud\n",
        "        )\n",
        "        SELECT \n",
        "            h.transaction_type,\n",
        "            h.fraud_value,\n",
        "            h.fraud_count,\n",
        "            ROUND((h.fraud_value * 100.0 / t.total_fraud_value), 2) as percentage_share,\n",
        "            t.total_fraud_value\n",
        "        FROM h1_2023_fraud h\n",
        "        CROSS JOIN total_fraud t\n",
        "        ORDER BY h.fraud_value DESC\n",
        "        \"\"\"\n",
        "        \n",
        "        try:\n",
        "            result_df = pd.read_sql_query(test_sql, conn)\n",
        "            print(f\"SQL query executed successfully!\")\n",
        "            print(f\"Result shape: {result_df.shape}\")\n",
        "            print(f\"Result data:\")\n",
        "            print(result_df)\n",
        "        except Exception as e:\n",
        "            print(f\"SQL query failed: {e}\")\n",
        "    \n",
        "    conn.close()\n",
        "else:\n",
        "    print(f\"Database file not found: {db_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
